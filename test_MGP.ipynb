{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "test_LVM_layers(2).ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Alonso94/GSoC-DGP/blob/master/test_MGP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pTFW0R7LrmW5",
        "outputId": "edb8bb6d-cd5b-4b46-c345-d56e354c3e28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%load_ext tensorboard\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_probability as tfp\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from tensorflow_probability import distributions as tfd\n",
        "from tensorflow_probability import positive_semidefinite_kernels as tfk\n",
        "\n",
        "%pylab inline\n",
        "plt.rcParams['axes.facecolor']='white'\n",
        "%config InlineBackend.figure_format=\"png\"\n",
        "\n",
        "logdir = \"logs/\"\n",
        "\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Populating the interactive namespace from numpy and matplotlib\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "K7j5heiFrq-t",
        "colab": {}
      },
      "source": [
        "#sess=tf.InteractiveSession()\n",
        "dtype=np.float64"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5WlzYSgtrtF8",
        "outputId": "a3813042-386d-483d-d3a9-d768ff45e2a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "# test matplot\n",
        "plt.figure(figsize=(12,4))\n",
        "x=np.linspace(-1.25,1.25,200)\n",
        "y= np.sin(3*np.pi*x)\n",
        "y=y+np.random.normal(loc=0,scale=np.sqrt(0.1),size=200)\n",
        "plt.plot(x,y,'*')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAssAAAD4CAYAAAAaeavxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3df7AdZZ3n8c/33pDEyA8xufyI8XKlwJSYGVFSxF3YKRAdkJ0hwUUGdRmZkgquUlbt1hTGSnbccjMlM3/MOqg1hkJLNBPUcTeYMWScIS6Ku2NIHJkNSEUySK5hxEQiMgyGSO53/7jnxJOT0+f0Of1099Pd71dVintzD+f0TT/99Lef5/t8H3N3AQAAADjRWNkHAAAAAMSKYBkAAABIQLAMAAAAJCBYBgAAABIQLAMAAAAJ5pR9AP0sWrTIp6amyj4MAAAA1Nj3vve9n7n7RK+fRR0sT01NadeuXWUfBgAAAGrMzPYl/Yw0DAAAACABwTIAAACQgGAZAAAASECwDAAAACQgWAYAAAASECwHdOC5w7p+w9/rwL8cLvtQAAAAEADBckB3bH9cO588pDvuf7zsQwEAAEAABMsBLF23TVNrtmrjjmm5Sxt3TGtqzVYtXbet7EMDgOgwC4c80K6QF4LlAB687XJdc+FizT9p9p9z/kljWnnhYj344ctLPjIAiA+zcMgD7Qp5iXoHv6o449T5OmXeHL340ozmzRnTiy/N6JR5c3TGKfPLPjQAiMbSddv04kszx77fuGNaG3dMa96cMe1Z//YSjwxVRrtC3oKMLJvZ58zsgJk9kvDzy8zsF2b2cOvPH4X43Jj87PkX9Z4V52jzBy7Re1aco4PPv1j2IQFAVJiFQx5oV8hbqJHlz0v6lKQv9HnNg+7+O4E+Lzobblx+7Ov1q5aVeCQAECdm4ZCHYdrVgecO69Z7vq9PvfuNtDukFmRk2d2/LelQiPcCANQXs3DIQ9p2RV4zRmHuHuaNzKYkfd3dTxhWNbPLJP1PSfsl/bOkP3T3RxPeZ7Wk1ZI0OTl50b59+4IcHwAAaKbuvOY28prRZmbfc/flvX5WVDWMf5B0jru/QdInJd2b9EJ3v9Pdl7v78omJiYIODwAA1BV5zciikGDZ3Z9z9+dbX98n6SQzW1TEZwMAgGYjXx5ZFFI6zszOkvRTd3czu1izQfozRXw2AABAO6/53RdPatND0zrI5iVIKUiwbGb3SLpM0iIz2y/po5JOkiR3/4yk6yT9JzN7SdIvJd3goZKlAQC5oHIA6mSUqlVcA5DCVcN4l7uf7e4nufsSd/+su3+mFSjL3T/l7q939ze4+5vd/f+G+FwAQH5CVg5gK2JUEdUzIAWshpGH5cuX+65du8o+DABolDwqB6zbvFt/+dC03nPxpNZf+xtZDxHIFdUzmqdfNQyCZQDAcQ48d1jr73tMf/vo0zr8qxnNP2lMV77+LK39968beiqaoANVFPIaQDXEUDoOAFARISsHULILVUT1DHQiWI4IOX0AYhFqpz2CDlQVu02ijTSMiJDTB6CObvniLk2cMv+4kl2dlQkAoGzkLEeOnD4AAIDykLMcOXL6AAAYDqmLKArB8ghCX6Dk9AGIHYEJYkMNZBSFYHkEeVygLCQAEDMCE8Ri6bptmlqzVRt3TMtd2rhjWlNrtmrpum1DvQ8PgEiLnOUhkFsMoGno9xCbUDWQ81hUz/bY1UXOciDkFgNoGvo95GnY0d12MDpnzEZOXQw1Mt0LMzD1RLA8BHKLkSemBBEj+j3kadjgsv36nT86NHLqYh4PgHkG4CjfnLIPoGraucWd9UKHwRQNknTeNKizjZhk7feAbt3pPRt3TGvjjunE9J7u1//457/Uxu/u01/t+vHQ6UB5PAA+eNvliakhqD5ylgvGxiPoNignlAcsAHUzbN5xqDzltqwb5fTql9du3q1ND01r7viYjhyd4T5fMf1ylhlZLsCB5w5rxce3q/O5ZNBTNJpj0IgEI84A6mbY0d3Qo8GdgfH6VcuG/v979cvMwNQXwXIB7tj+uNylqYUL9PRzh5miwXGSbgL/7k/+91DTlABQJcMGlzEEo2nTR0YJwBEv0jBylDS9LklmYooGx/SaEvzvK5cFnXYEAGQTOh0E8SANoyTd0+tjJk2+coHWX7tMf/PIT5miwTFJU4KxViEgjxpAE1EdppkIlnPUfVEdOTqjS89bpEvPm9Cl502UfXiogBimHXshjxpAU8XaLyM/pGHkLOuKW2BYeY76sptbPeXVZpiBQBXRbpuJHfxKtOHG5Vq/apkuWHyq1q9aRqCM3OW5gxS7udVTXm0my/uySQ/Kwi586MbIMlATRY36Uku0PvJqMyHel5r0KBozZ83GyDLQAEWN+rbz9UbZZhZxyavNZHlftg1GWZg5Q5IgC/zM7HOSfkfSAXc/obigmZmkP5d0taQXJN3k7v8Q4rMBzCpqlXbWYv6IR15tJsv7sm0wykKlCyQJNbL8eUlX9fn52yWd3/qzWtJfBPrcXJEzh9gMapOM+mJYebWZUd+XgAVlog9FL8Fyls1sStLXE0aWN0h6wN3vaX2/R9Jl7v6Tfu9Zds4yOXPI27Crrstsk6wQR1GoIgSgaP1ylosKlr8u6XZ3/07r++2SPuzuJ0TCZrZas6PPmpycvGjfvn1Bjm8YJPmjKGmD37LaZGeAfMf9j/PwiOB4CAMQg0oFy53KGllmO0vkbdjgt6w2uW7zbm3cMd3zZzw8NlfIAJcZPAAxiGG766ckvbrj+yWtv4tSbDlzjLzUz7CLmIpuk0nBvCQWXCHIDo7dbWzjjmlt3DHNQxiA6BRVOm6LpN+3WW+W9ItB+cpliynJnwLp9TNK8Ftkm+wuoTRus38/N4KHR5QnZFk3ynQBqIpQpePukXSZpEVmtl/SRyWdJEnu/hlJ92m2bNxezZaO+4MQn5unGMpjMfJSb+3gt3MRUz9FtslewfxrzzhZn7jhjX2PlVmQegtZ1i22GTxgEPq35goSLLv7uwb83CV9MMRnNQn1RusthgeyfnoF8+1t25OEmJ5HvEIHuMM+MAKjCBXk0r81F9tdZ5T3kyZbCyOkvNorFWSag7JuqJqsi0jp35qhkGoYeahCsJzXSu52ULNg7riWnL6AGxOCSNNeRwmoqSCDEJjmRkihglz6t2boFywXtcCv8rp3Thu00CXr7n/t6Z4lr3iZ1q9admz6uzNQZofBZhvm/A+zMGuUBaXkn0IK1++xmBkhhFpESv8GguWUujvxQRfhqJ1+3kEN6mOY85/mppG10kFMFWRQjiL6PSCtkEEu/VuzkYYxQL9pnOsuWnJCPvFffW9/pmmfNNM95E8126jnf1D+O1ONGMWB5w5rxce3q9etJGS/B4yCHHukRRpGBv1G5Ho9aWad9knzJEx90mYb9fwPGhlhqhGjuGP743KXphYuyLXfayP9DMPYcOPyxFRGIK2idvCrrH6deFLpr6wBx6BySgQ19ddvodOo5z9NqTpKeSGt7hmOJ5954djXefR7bZTvAlA0guUUhg0gsgYcBDUYFBCEPv+9gvMYaz8jHt114MdMmnzlAq2/dpn+5pGfBu/32KQJsaKKS/2RswxEpKx89LxKIKLeiqwDT14zYkX/WQ/9cpYZWQYiUvSujYzWIYsiZ7hIP0Ns6D+bgwV+JWOxCjoVHRCwWBRZFL14ivJdiAn9Z3MwslwyFqugW8jRukG5dIzWoUrSrOcAikL/2RwEyyUZdfqGhQT1FzIgSPMwxmJRAHlowv2K/rMZWOBXklEXq7CQAGmwcQ2AsnG/QpWwwC9Cw07fsJAAwyh6oSAAtHG/Qt2wwK9EwyxWYSFB9ZS5eJNcOgBlCXG/YvE7YkKwXKJhVpIT/FRPZ75wGagcAKAMIe5XRfefBOfoh5zlLjEvSLjli7s0ccr84xYSsM99fMgXBtB0o96v2JgJZemXs0yw3IULBlmx0xgAjKbo/pPBDbT1C5ZJw2hZum6bptZs1cYd03KfXZAwtWarlq7bVvahoWLKSJmJcQoxxmNCNdGWmoONmRAjguWWul4w3GTKUXS+cJn50UltrOycbdQHbalZQvSfae99rAdCGqRhdFi7ebc2PTStueNjOnJ0phapGKSV1FsMU4jdbSyGY0I90JYgjbaWaJh7H+uBIJGznFqdLhhuMs1QZn50UhubO2666jfOJmcbmZH/D2m4wJd7H0aVe86ymV1lZnvMbK+Zrenx85vM7KCZPdz6c3OIzw1tmFJusatrWgmOV+YUYlIb+86atzCtiSCYIm+2UdYSce9DHjLv4Gdm45I+LeltkvZL2mlmW9z9B10v/bK735r185AON5nmaOf3dc6IFKFfGyvrmFA/tKXmGmUnUu59yEOI7a4vlrTX3Z+QJDP7kqSVkrqDZRSMm0wzdM6ArF+1rNDPTmpjZR4T6oW21FyjBr7c+xBa5pxlM7tO0lXufnPr+xslregcRTazmyR9XNJBST+U9J/d/ccJ77da0mpJmpycvGjfvn2Zjg8AkF7MGzONom6/T531Old1WkuEuMVQZ/mvJU25+29K+jtJdye90N3vdPfl7r58YmKioMOrPkrEAQihbmXa6vb71Fmvc1WntUSorhAjy/9G0n9z9ytb339Ektz94wmvH5d0yN1PG/TeZezgV1WUiAOQRd2qCNTt96kzzhVikPfI8k5J55vZa8xsrqQbJG3pOoCzO769RtJjAT4XYudBjI7ZCHSqWxWBuv0+dca5QuwyB8vu/pKkWyV9Q7NB8Ffc/VEz+5iZXdN62YfM7FEz+0dJH5J0U9bPxSw6GYyK6Wl0qlsVgbr9PnXGuULsQlTDkLvfJ+m+rr/7o46vPyLpIyE+C8fr1cmMm+nWTSxoQW/dU54bd0xr445ppjxRuyoCdft96oxzhZixg18NdK8W/taeA9r/7C/JX0ZP7IoGIC9UH0FV9ctZDjKyjHK1VwczYhivmG4gTHkCyEtneheDNagLguUaGWW3IxQjthsIU54AQmKwBnVGsFwjjBjGJ9YbCLuiAQiJwRrUWVGbkqAg7RHDzR+4RO9ZcY4OPv9i2YfUaFQrSY9SdkB1MViDOiNYrhl2O4oLN5D0KGUHVBuDNclGGQxgACEepGE0SEyLzJqE/OD+Yk1VQf3QB+aL9K5ko6xbiW2tS5NROq5B2BIbMaKUHYpCH4iijbKVN9t/l4PScQ3HyB1i0j26R6oKQutuY0l9oEnasfYK2hpyM+zCxwPPHdbrzj5VZ546T9/64UEWS0aCnOUGYJEZYtIrN5lcx/w0Me+xu4316gOnFi6QTOTII1fDDgbcsf1x/eP+Z/XEwX9lACEijCw3ACN3iEHaGQ5yHcNqUt5jvzZ23UVLjv3s8K9m9OQzL5zwGmba8tPEfPH277xg7vjAdSvdbffxA89LkmbcZwcQGvSwGyNylhuie0vsg/9ymEoZKBS5ycVqYt5jvzb2X+99RBOnzNdVrz9L6+7drelDL2jGRTssSBPzxYf5nekfy0fOMlilHJEmjrBIzHAUrWmbRLSvqyWnv6xnG+vsAy85b5H2PTRNOyxAE9fMjPI70z/GjZxloGBNridMbnJxmnbzbV9XO390aGAbox1mlzYXvle++JWvP1MXLD61tnn0o64Tol3GizQMoCBNnBZHuZqQfsV1VY5hUgzWbt6tTQ9Na+74mI4cndF5Eydr78Hna52S0f071/l3rYt+aRgEy0BByEkDwgtxXTU1NWoUozyctB/avrxzWr86emLMUccHmyY8qNZNv2CZNAygIE2bFkfc6lJSLsR11eTUqGGNkmKw4cblWr9qmf7Ph9/SmDKm7d/5gsWnav2qZccFynW59pqEYBmJuKDDIycNsahTgDjqdbV03TZNrdmqjTum5T67EGtqzVYtXbct5yOuriwPJwwYzCri2uP+HRZpGEjUxFI/QN2R4/trpEaNJkuKQZPTE4q89rh/D4+cZQyFmylQXwSIx2MhVnbkfKdTxLXH/Xt05CxjKGyPDdQXU+HHIzUquzql9OSpiGuP+3c+2JQEJ+BmirIxUpWvdoDYb/vdpmDDptE1ccORrPK+9rh/54M0DPTU5LyyYRHYDTbsvxH5dkD8SOmJE/fv0eSes2xmV0n6c0njku5y99u7fj5P0hckXSTpGUm/5+5PDnpfgmVUAYHdYGn/jci3A6qFnG/URa7BspmNS/qhpLdJ2i9pp6R3ufsPOl7zAUm/6e7vN7MbJF3r7r836L0JlhEzArvBhv03YqQKqBZGMeuBGdL8F/hdLGmvuz/h7kckfUnSyq7XrJR0d+vrr0q6wswswGcjAOoxjoaFFIMN+29Evh1QLf0230B1sEizvxAL/F4l6ccd3++XtCLpNe7+kpn9QtJCST/rfjMzWy1ptSRNTk4GODwM0nmRMH2WHoHdYKP8G7H4DACKwSLNdKKrhuHud0q6U5pNwyj5cGqNiyS77sBu/6F/1fUb/r7RU1ndhg1+qU6AWDA1jbp78LbLE1Pf8Gsh0jCekvTqju+XtP6u52vMbI6k0zS70A8lIo0gu+4pyCWnL2Aqq0vWaVrShFAWpqZRd8yQphMiWN4p6Xwze42ZzZV0g6QtXa/ZIum9ra+vk/RNj7lmXUP0ukjGzXTrpu8HCUyaFOQsXbdNU2u2auOOabnPjtJPrdmqpeu2lX1oUUvTRghYULSk6/m1a+9rTJ+G5mBjnsEyB8vu/pKkWyV9Q9Jjkr7i7o+a2cfM7JrWyz4raaGZ7ZX0XyStyfq5CKP7Itn55KFggUmTghxG6UfTr43wABJe3R5g8/p9kq7n333D4sb0aWgOFmkOxqYkkBS2DFpTS6pRbzS9NG0kSxk5ck17q1tN8Dx/n87ruVdblerfpyEenX2aXPRvOci7dBxqIOTIaFNHWZnKSi9NG8mSS9ekWY006jZKX8Tv03k9v+NNr9JZp81LbK91G7FHfDr7NPq34kVXDQPlCJnk34QFA71GLqnikF7aNjJsJY0QFV7qOCpdtxXvRfw+ndfzn11/4bGR5l7tlfKbyEuvPq3zaypYFYNgGceErG9b91q53ByzS9NGhn0ACRFE1fHc1u0Btozfp1d7pfwm8tbdp42ZZJKOuir/0Fsl5CwDQ2hqPnaVjJo7XvdzW7dtiWP4fdieHUXolT8/bw5rY0Lrl7PMyDIwhLpNZ9fRqLMadT+3dUsTiuH36Vd+s05pPChXZ592yxdnBxA33Li8lrO2sSJYBoZQt+nsOho1iOLcYhTdD2ff2nNA+5/9Za3SeFCuzj7twQ+/5djXdXjorQqCZWBIdc/HrpLQi/E4txhWO5BpQv5yHRe/AmmQs9xQdHqog7rVDUZ1NSF/mesNdUbOMk5QxxX/aI4mjOKhWuqcxsP1hqZjU5KGqdvmBEVi44F4NHXjG8StrhsTcb2h6QiWG4ZOb3TsmhSPOo/ijYqHufJtuHG51q9apgsWn6r1q5ZVujRfJ643NB3BcsNUvdMrIyBgND5OdR3FG1XnwxyBM0LjekOTscCvgWIo5j+qMhaYNGHhDsoRYqFt0mYqkvQfV7AQC+mw6Lsc/LvHo98CP4JlVELZu6uNuisc0E+Ih7/uh7leWIiFQah0UQ7+3eNBsIzKK3t0t8qj8YhP6Ie/9sPcSWOmI0dd42OmozPOLAgGKnsgoqn4d49Pv2CZnGVUQtm51nVduINyhF5o284nvfeDl+r8M07W0Rmv5JoEFI9F3+Xg3723WNdbUGcZlcHuaqiL0A9/nQ9v5068XCvOXch1glTKHohoKv7de4t1DwiCZVRGZ0CwftWyEo8EyC6vhz+uEwyLgYhyFPXvXoVFhLFvfEPOMgAAQE3FsoiwX9Be9rokiZxlAIhGrDl5AOoltj0C+m3sFXtaCmkYAFCgWHPyANTLg7ddnjhaW6S0KRYxpwMRLGNoVch/AmITe04egHqJZbQ2bdAe83oL0jAwtH5TKQB6o1QUgKLFsE15LEF7FplGls3slZK+LGlK0pOSrnf3n/d43VFJu1vfTrv7NVk+F+VgZAwYXZobBrM2AEKKZbQ25hSLNDJVwzCzP5V0yN1vN7M1kk539w/3eN3z7n7ysO9PNYy4xLBaFaiyQTtBxrJqHQCapl81jKw5yyslXdb6+m5JD0g6IVhGPdRhKqWNEbxqqvp5SxrlYdYGQBGq3oeWJWvO8pnu/pPW109LOjPhdfPNbJeZfdfMVvV7QzNb3XrtroMHD2Y8PIQWQ/5TCORdV1Ps523UsnDkMwMoQux9aKwGpmGY2f2Szurxo7WS7nb3V3S89ufufnqP93iVuz9lZudK+qakK9z9nwYdHGkYCK17BK+NEby4VeW8ZUmjWLt5tzY9NK2542M6cnSGVAwAwVSlDy1Tpk1J3P2t7r6sx5+vSfqpmZ3d+pCzJR1IeI+nWv99QrOpGm8c8XcBMmEEr5piP28hiv/XZdYGQDn6zWwV1YfWddOlrGkYWyS9t/X1eyV9rfsFZna6mc1rfb1I0iWSfpDxc4GR1CnvukliP28hbkQbblyu9auW6YLFp2r9qmXH5TcDwCAx7JBX1zSPrAv8bpf0FTN7n6R9kq6XJDNbLun97n6zpNdJ2mBmM5oNzm93d4JllGaYEjYshohHzKWHYg/mAdTTgecOa8XHt6szo7aMHfLqvkg5U+m4vJGzjLJRygtpDSoLBwChrdu8ezbta+ECPf3c4VzLuvYbPKpDadk8S8cBtVT3p2SEF0vxfwD1132PevKZF459XUSKRffgUd1n19juGugh9gVlAOJX18VOKF/3PWrMpKmFC7Tx5ouDLxBOu4C5zouUGVkGeqj7UzKA3kKuU+g3Egdk0X2POnJ0Rpeet0iXnjehS8+bCPpZD952eWKKhdT7mqnb7Bojy0iliSMkdX5KRjZNvB6aIsRq/hClBIFBirpHDRo8qmsFjE4s8EMqLHQDfq2I64FKLMUKuWnDMIudYjzPMR4TytVrAfMDew7WaqMTFvhhZCx0A36tyOuBKfxiDZpqHsYwaVwxnucYjwnl6rWAud9DYd0QLKOvkDcQoOqKuB54QC1H6HUKg2raxnieYzwmxKtJa3vIWUZfTboYgEFGvR6GyXGmEkt5QuaADtqRMcbzHOMxIW5NWdvDyDIGinnnNKBoaa+HzrzPYaa1eUAtT5G1smM8zzEeE+LWlPryLPADgBy0d9bqZdC0NrsBNkOM5znGYwKK0G+BH8EyAASUVFVB0shbwCZVJ6BqAdpoC0A2/YJlcpZRWdS6RYy68z7Hbfbv52aY1u5M4+hs902ob4pktAWUpWn3X0aWUVmhat0yIoPQ1m7erU0PTWvu+GyA/NozTtYnbnjj0NPa/Uape6FqQbNkSfUBsqjj3gukYSAqWYPTkJsHSPW86FGuUHmf3XVMk4ya3oFqyiPVB0gj9P03JqRhICpZpwtDlTdiS1qE0Gs6clDZsLQ6qxPMbeVzjI+1/hsgvQPVlEeqD9DWL8WiqeUFCZZRmGGC034Xa6jyRk296BFW3rmi7VJ1937wUp1/xsk6OuOaN2dMR1167Rkn696a1zfFibr7QNoCQurXp4W6/1Yt55k6y8hkmJSKYXY/G1SXNkTtZ2qKIouidjvrHJU+d+LlWnHuwuPafXv0GtURYp1Erz6QtoBhdLfDtH1aiPtv1bZUJ2cZmQyb79u58OnI0ZkT/r+i86GoKYpRdecTkyuKtFgngRh0t8Mi+rSYc5775SwzsoyRjDqqNuiJdJjR5zQGjeA0ZfchhMfMBIZV1GxEEir/QOrfDq+7aEmufVroe3xRyFnGSJLyfTd/4N/2zUPqt/Cp3ZHPGbNgFyu1R5Gn9sPfZnJFkULZ6yToDyH1b4d592lVHWRgZBkjSWrwm3ZMj5yH1O7If/LsyzLnQyU9OZukHWuviP7CRD5Cj6wxM4FhlBUoJPWHc8dNF06ezkhzw/Rrh0X0aSFynotGzjJG1pnv+7uf/I6O9mhLaaYX88hh6pV7ddap87Xv0AvkCTYYuaIoWxHrJLofCpNyUeeMmf7X95/iemgg1uuciE1JkLssCwPyWlTQXkyY1MR7BePk9NVTzItKgNB6PRR27yrZC9cDmiy3TUnM7J1m9qiZzZhZ4iOJmV1lZnvMbK+ZrcnymYhTlunFvKYm21M9G9+3QlMLF6i1l0PfPEFy+uqp7FxRoAj9atl35qK+402v0lmnzeN6AFLKmrP8iKR3SNqQ9AIzG5f0aUlvk7Rf0k4z2+LuP8j42YhMljykkDlMvUaHLzlvkfY9NJ0YjJe9Sh35abeHJae/7LgHsnEz3bqJWQTUR79KA51t/M+uv/DYSPOgAQpm24CMI8vu/pi77xnwsosl7XX3J9z9iKQvSVqZ5XMRpyxb/IbaHljqPTo8aIUvI4/11W4PO3906Lg2sPPJQ0PNIlRtxylUW2d7S9v2hpmlS1v1gNk2IFDOspk9IOkP3f2EBGMzu07SVe5+c+v7GyWtcPdbE95rtaTVkjQ5OXnRvn37Mh8fmiFrXuqgDVNQLUntIcmgdsLiQBSps71JSt32Qi3cIs8fTZNpgZ+Z3S/prB4/WuvuX2u95gEFCpY7scCvPoqYysu6UJDVwfWS1B5u+a1z9ZlvP5G6nRA0oJe8+rQ0D3lFtD12qETTZFrg5+5vdfdlPf58LeXnPyXp1R3fL2n9HRqkiKm8rAsFQ6aCoHxJ7eGCxacN1U5I0UEvefVp3e1tzKTxFIuTQ6vq5hFAHorYlGSnpPPN7DWaDZJvkPTuAj4XEShq4Vx7lGfB3PHKFTtHfpIWjg6zoJSgAZ3y7tN6tTdJpbS9Km4eAeQhU86ymV0r6ZOSJiQ9K+lhd7/SzBZLusvdr2697mpJn5A0Lulz7v7Had6fNIzqK2oqj3xS5IkUHbQV0ad1trdbvjh7D9xw43LaHpAjNiVBqfJcOEc+KYCisRgYqJ/cNiUB0khbomgU5JOijdJuKEqefRqA+BSRs4yG65wyXL9qWdD3Jp8UbZ0LrhjlQ55G6dPY3AOoLoJlVB6LUJqN3RdRBTzMAdVFzjKASqMeLGLGugqgv1hmXchZBlBbpOIgZqyrAPqrwpbqpGEAqDxScRArHuaA3qqUQsfIMlD067YAAAakSURBVKJHlQMMknX3RdoY8kT1DOBEVZp1IVhG9KowRYNqS2pjBNEIIevDHFBHVZp1IQ0D0arSFA2qaVAbo4IBipRmoVMsi6GAEKqSQkc1DESLKgfIW1Ib2/bI0zpCBQMUbN3m3frLh6b77giY5jUAhtevGgYjy4hWlaZoUE1Jbew7t12e+KAGhJZmFo2ZNqA85CwjaiyMQd56tTEe1FCkNAudqrQYCqgbRpZRqkH5d3lulQ1IyW2sKrl0qL40D2c8wAHlIVhGqVhAhVjxoIYipXk4G+UBjgWBQHYs8EMp2AIWAPLHgkAgnX4L/AiWUQoqXQBAfhiQAIbTL1hmgR9KQf4dAOSHBYFAOOQsozQsoAKAfDAgAYRDsIzSsIAKAPLDgATKVpcFpuQsAwAAILgqLTBlBz8AAAAUom47TrLADwAAAMHUbYEpwTIAAACCqdsC00zBspm908weNbMZM+uZ59F63ZNmttvMHjYzkpABAABqrL3AdPMHLtF7Vpyjg8+/WPYhjSxrzvIjkt4haUOK117u7j/L+HkAAAAoQJZqFnWqeJVpZNndH3P3PaEOBgAAAHG4Y/vj2vnkId1x/+NlH0qpiqqG4ZL+1sxc0gZ3vzPphWa2WtJqSZqcnCzo8AAAACDVr5pFVgNHls3sfjN7pMeflUN8zqXu/iZJb5f0QTP7raQXuvud7r7c3ZdPTEwM8REAAADIqm7VLLIaOLLs7m/N+iHu/lTrvwfMbLOkiyV9O+v7AgAAIKy6VbPIKvfScWb2cjM7pf21pN/W7MJAAAAARKhO1SyyyrTdtZldK+mTkiYkPSvpYXe/0swWS7rL3a82s3MlbW79L3MkbXL3P07z/mx3DQAAgLzltt21u2/WrwPhzr//Z0lXt75+QtIbsnwOAAAAUAZ28AMAAAASECwDAAAACQiWAQAAgAQEywAAAEACgmUAAAAgQabScXkzs4OS9pV9HA2xSNLPyj4I5I7zXH+c42bgPDcD57k457h7z62jow6WURwz25VUXxD1wXmuP85xM3Cem4HzHAfSMAAAAIAEBMsAAABAAoJltN1Z9gGgEJzn+uMcNwPnuRk4zxEgZxkAAABIwMgyAAAAkIBgGQAAAEhAsNxQZvZOM3vUzGbMLLEsjZldZWZ7zGyvma0p8hiRnZm90sz+zsweb/339ITXHTWzh1t/thR9nBjeoGvTzOaZ2ZdbP99hZlPFHyWySnGebzKzgx3X781lHCdGZ2afM7MDZvZIws/NzO5otYH/Z2ZvKvoYm45gubkekfQOSd9OeoGZjUv6tKS3S7pA0rvM7IJiDg+BrJG03d3Pl7S99X0vv3T3C1t/rinu8DCKlNfm+yT93N3Pk/Q/JP1JsUeJrIbog7/ccf3eVehBIoTPS7qqz8/fLun81p/Vkv6igGNCB4LlhnL3x9x9z4CXXSxpr7s/4e5HJH1J0sr8jw4BrZR0d+vruyWtKvFYEE6aa7Pz3H9V0hVmZgUeI7KjD24Ad/+2pEN9XrJS0hd81nclvcLMzi7m6CARLKO/V0n6ccf3+1t/h+o4091/0vr6aUlnJrxuvpntMrPvmhkBdfzSXJvHXuPuL0n6haSFhRwdQknbB/+H1vT8V83s1cUcGgrEvbhkc8o+AOTHzO6XdFaPH611968VfTzIR7/z3PmNu7uZJdWKPMfdnzKzcyV908x2u/s/hT5WAMH9taR73P1FM7tFs7MJbyn5mIBaIViuMXd/a8a3eEpS5yjFktbfISL9zrOZ/dTMznb3n7Sm7Q4kvMdTrf8+YWYPSHqjJILleKW5Ntuv2W9mcySdJumZYg4PgQw8z+7eeU7vkvSnBRwXisW9uGSkYaCfnZLON7PXmNlcSTdIolJCtWyR9N7W1++VdMKMgpmdbmbzWl8vknSJpB8UdoQYRZprs/PcXyfpm84uVFUz8Dx35a5eI+mxAo8Pxdgi6fdbVTHeLOkXHel1KAAjyw1lZtdK+qSkCUlbzexhd7/SzBZLusvdr3b3l8zsVknfkDQu6XPu/miJh43h3S7pK2b2Pkn7JF0vSa1yge9395slvU7SBjOb0ewD9O3uTrAcsaRr08w+JmmXu2+R9FlJXzSzvZpdPHRDeUeMUaQ8zx8ys2skvaTZ83xTaQeMkZjZPZIuk7TIzPZL+qikkyTJ3T8j6T5JV0vaK+kFSX9QzpE2F9tdAwAAAAlIwwAAAAASECwDAAAACQiWAQAAgAQEywAAAEACgmUAAAAgAcEyAAAAkIBgGQAAAEjw/wEVynFej/lwwQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 864x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "o9xBRiyZFws9",
        "colab": {}
      },
      "source": [
        "layer_count=0\n",
        "DGP_count=0\n",
        "class Layer:\n",
        "    loss=None\n",
        "    # input size for the next layers will be equal to the latent variable size of the previous layer\n",
        "    def __init__(self, sess, input_size, output_size, DGP_output_size, input_layer=False, limit=1.25,\n",
        "               a_initial_val=1.0, ls_initial_val=1.0, obs_nv_initial_val=1.0):\n",
        "        global layer_count\n",
        "        layer_count+=1;\n",
        "        global DGP_count\n",
        "        self.output_size=output_size\n",
        "        self.input_size=input_size\n",
        "        self.layer_count=layer_count\n",
        "        with tf.variable_scope(\"DGP_{}_layer_{}\".format(DGP_count,layer_count)):\n",
        "            # generate training variable of the layer\n",
        "            # a - amplitude\n",
        "            # ls - length scale\n",
        "            # obs_nv - observation noise variance\n",
        "            # these variables will be optimized during the training\n",
        "\n",
        "            # finfo : Machine limits for floating point types\n",
        "            # tiny : The smallest positive usable numbe\n",
        "            # softplus: a smooth approximation of a rectifier \n",
        "            # rectifier(x) = max(0,x)\n",
        "            # softplus(x) = log(1+exp(x))\n",
        "            tiny=np.finfo(np.float64).tiny\n",
        "\n",
        "            a_variable=tf.Variable(initial_value=a_initial_val,name=\"amplitude\",dtype=dtype)\n",
        "            self.a=(tiny + tf.nn.softplus(a_variable))\n",
        "\n",
        "            ls_variable=tf.Variable(initial_value=ls_initial_val,name=\"length_scale\",dtype=dtype)\n",
        "            self.ls=(tiny + tf.nn.softplus(ls_variable))\n",
        "\n",
        "            obs_nv_variable=tf.Variable(initial_value=obs_nv_initial_val,name=\"observation_noise_variance\",dtype=dtype)\n",
        "            self.obs_nv=(tiny + tf.nn.softplus(obs_nv_variable))\n",
        "\n",
        "            # use Exponentiated quadratic kernel\n",
        "            # or could be called squared exponential, Gaussian, or radial basis function\n",
        "            # k(x, y) = amplitude**2 * exp(-||x - y||**2 / (2 * length_scale**2))\n",
        "            self.kernel = tfk.ExponentiatedQuadratic( self.a, self.ls )\n",
        "\n",
        "            # define the number of the inducing points\n",
        "            self.num_inducing_points=50\n",
        "\n",
        "            # we have to make trainable inducing points\n",
        "            init_inducing=np.linspace(-limit,limit,self.num_inducing_points,dtype)[...,newaxis]\n",
        "            self.inducing_ind_pts=tf.Variable(init_inducing,dtype=np.float64,name='inducing_index_points')\n",
        "\n",
        "            init_loc=np.zeros([self.num_inducing_points],dtype=dtype)\n",
        "            self.variational_ind_obs_loc=tf.Variable(init_loc,name=\"variational_inducing_observations_loc\")\n",
        "\n",
        "            init_scale=np.eye(self.num_inducing_points,dtype=dtype)\n",
        "            self.variational_ind_obs_scale=tf.Variable(init_scale,name=\"variational_inducing_observations_scale\")\n",
        "\n",
        "            self.input_placeholder = tf.placeholder(dtype, [None,input_size], name='layer_input')\n",
        "#             self.output_placeholder = tf.placeholder(dtype, [None,DGP_output_size], name='layer_output')\n",
        "            \n",
        "#             self.loss_placeholder = tf.placeholder(dtype, () ,name='loss_input')\n",
        "\n",
        "            self.posteriors=[]\n",
        "            self.priors=[]\n",
        "            self.optimizer=[]\n",
        "            self.train_op=[]\n",
        "            self.loss=[0.0]*output_size\n",
        "            \n",
        "            # construct the VGP distribution(s)\n",
        "            for i in range(output_size):\n",
        "                \n",
        "                self.posteriors.append(tfd.VariationalGaussianProcess(kernel=self.kernel, \n",
        "                                                                        index_points=self.input_placeholder,\n",
        "                                                                        inducing_index_points=self.inducing_ind_pts,\n",
        "                                                                        variational_inducing_observations_loc=self.variational_ind_obs_loc,\n",
        "                                                                        variational_inducing_observations_scale=self.variational_ind_obs_scale))\n",
        "\n",
        "                self.priors.append(tfd.GaussianProcess(tfp.positive_semidefinite_kernels.ExponentiatedQuadratic(),\n",
        "                                                           self.input_placeholder))\n",
        "                \n",
        "#                 prior=self.priors[i]\n",
        "                    \n",
        "            \n",
        "#                 # compute the lower bound terms\n",
        "#                 ################################################\n",
        "#                 ##\n",
        "#                 ##   (Equation 17 - Doubly stochastic DGP paper)\n",
        "#                 ##\n",
        "#                 ################################################\n",
        "#                 #self.variational_posterior=sess.run(self.variational_posterior,feed_dict={self.input_placeholder: X})\n",
        "                \n",
        "#                 variational_posterior=self.posteriors[i]\n",
        "                \n",
        "# #                 # compute the log probabilities\n",
        "# #                 log_probs = self.posteriors[-1].log_prob(self.output_placeholder)\n",
        "\n",
        "# #                 # Reduce sum over the data dimensions\n",
        "# #                 likelihood_term = tf.reduce_sum(log_probs,axis=-1)\n",
        "\n",
        "# #                 # Reduce mean over the batch dimensions\n",
        "# #                 likelihood_term = tf.reduce_mean(likelihood_term)\n",
        "\n",
        "#                 # Compute the KL divergence term\n",
        "#                 kl_term = variational_posterior.kl_divergence(prior)\n",
        "\n",
        "#                 # Reduce over the dimension.\n",
        "#                 kl_term = tf.reduce_mean(kl_term)\n",
        "                \n",
        "#                 self.loss[i] = self.loss_placeholder - kl_term\n",
        "\n",
        "#                 self.optimizer.append(tf.train.AdamOptimizer())\n",
        "#                 self.train_op.append(self.optimizer[i].minimize(np.abs(self.loss_place_holder)))\n",
        "                \n",
        "            \n",
        "    def _sample(self,sess):\n",
        "        samples=[]\n",
        "        for posterior in self.posteriors:\n",
        "            samples.append(posterior.sample())\n",
        "        return samples\n",
        "    \n",
        "    def update_prior(self,sess):\n",
        "        for i in range(len(self.priors)):\n",
        "            self.priors[i]= self.posteriors[i]\n",
        "\n",
        "    def __call__(self, sess, x):\n",
        "        #self.variational_posterior=sess.run(self.variational_posterior,feed_dict={self.input_placeholder: X})\n",
        "        self.sample=self._sample(sess)\n",
        "        x=sess.run(self.sample,feed_dict={self.input_placeholder:x})\n",
        "        x=np.array(x).T\n",
        "        return x \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fAQf7y95L76D",
        "colab": {}
      },
      "source": [
        "class DGP:\n",
        "    def __init__(self, X, Y, num_hidden_layers=2, latent_size=1):\n",
        "        global DGP_count\n",
        "        DGP_count+=1\n",
        "\n",
        "        global layer_cont\n",
        "        layer_count=0\n",
        "\n",
        "        input_size=X.shape[1]\n",
        "        output_size=Y.shape[1]\n",
        "\n",
        "        self.input_size=input_size\n",
        "        self.output_size=output_size\n",
        "        self.num_hidden_layers=num_hidden_layers\n",
        "        self.latent_size=latent_size\n",
        "\n",
        "        self.X=X\n",
        "        self.Y=Y\n",
        "\n",
        "        self.layers=[]\n",
        "        \n",
        "        self.sess=tf.Session()\n",
        "\n",
        "        self.build_model(self.sess)\n",
        "        \n",
        "        self.input_placeholder=tf.placeholder(dtype,[None,self.input_size],name=\"DGP_input\")\n",
        "        self.output_placeholder=tf.placeholder(dtype,[None,self.output_size],name=\"DGP_output\")\n",
        "        \n",
        "        self.loss_ = self.loss(self.sess)\n",
        "        \n",
        "        self.optimizer=tf.train.AdamOptimizer(learning_rate=0.001)\n",
        "        self.train_op=self.optimizer.minimize(self.loss_)\n",
        "            \n",
        "        self.sess.run(tf.initialize_all_variables())  \n",
        "\n",
        "    def build_model(self,sess):\n",
        "        self.layers.append(Layer(sess,self.input_size,self.latent_size,self.output_size))\n",
        "        for i in range(self.num_hidden_layers):\n",
        "            self.layers.append(Layer(sess,self.latent_size,self.latent_size,self.output_size))\n",
        "        self.layers.append(Layer(sess,self.latent_size,self.output_size,self.output_size))\n",
        "    \n",
        "    def loss(self,sess):\n",
        "#         x=self.X\n",
        "        loss=0.0\n",
        "        kl_term=0.0\n",
        "        k=0\n",
        "        for layer in self.layers:\n",
        "            print(k)\n",
        "            k+=1\n",
        "# #             x=layer(self.sess,x)\n",
        "#             self.sample=layer._sample(self.sess)\n",
        "#             x=self.sess.run(self.sample,feed_dict={layer.input_placeholder:x})\n",
        "#             x=np.array(x).T\n",
        "            for i in range(layer.output_size):\n",
        "                kl=layer.posteriors[i].kl_divergence(layer.priors[i])\n",
        "                kl_term+=tf.reduce_mean(kl)\n",
        "            posteriors=layer.posteriors\n",
        "        lh_term=0.0\n",
        "        for posterior in posteriors:\n",
        "            lh=posterior.log_prob(self.Y)\n",
        "            lh=tf.reduce_sum(lh,axis=-1)\n",
        "            lh_term=tf.reduce_mean(lh)\n",
        "        loss = lh_term - kl_term\n",
        "        return loss\n",
        "    \n",
        "#     def optimize(self, X , Y,it):\n",
        "#         x= self.X\n",
        "#         x=x.reshape((-1,1))\n",
        "#         k=0\n",
        "#         lh_term=self.layers[-1].posteriors[-1].log_prob(Y)\n",
        "#         lh_term=tf.reduce_sum(lh_term,axis=-1)\n",
        "#         lh_term=tf.reduce_mean(lh_term)\n",
        "#         loss=self.sess.run(lh_term,feed_dict=)\n",
        "#         for layer in self.layers:\n",
        "#             k+=1\n",
        "#             x=x.reshape((-1,1))            \n",
        "#             feed_dict={layer.input_placeholder:x,\n",
        "#                           layer.loss_placeholder:loss}\n",
        "#             for i in range(layer.output_size):\n",
        "#                 loss+=self.sess.run(layer.loss[i],feed_dict)\n",
        "#                 self.sess.run(layer.train_op[i],feed_dict)\n",
        "#             layer.update_prior(self.sess)\n",
        "#             x=layer(self.sess,feed_dict)\n",
        "#             x=np.array(x).T\n",
        "            \n",
        "    def train(self,niter=100):\n",
        "        for i in range(niter):\n",
        "            x=self.X\n",
        "            feed_dict={}\n",
        "            for j in range(len(self.layers)):\n",
        "                feed_dict[self.layers[j].input_placeholder]=x\n",
        "                self.sample=self.layers[j]._sample(self.sess)\n",
        "                x=self.sess.run(self.sample,feed_dict={self.layers[j].input_placeholder:x})\n",
        "                x=np.array(x).T\n",
        "                print(self.sess.run([self.layers[j].a,self.layers[j].ls,self.layers[j].obs_nv]))\n",
        "#             print(feed_dict)\n",
        "            loss,_=self.sess.run([self.loss_,self.train_op],feed_dict=feed_dict)\n",
        "            print(i,loss)\n",
        "            \n",
        "#             x=input()\n",
        "   \n",
        "    def predict(self,X):\n",
        "        Y=[]\n",
        "        f_i=x\n",
        "        count=1\n",
        "        for layer in self.layers:\n",
        "            f_i=f_i.reshape((-1,1))\n",
        "            feed_dict={layer.input_placeholder:f_i}\n",
        "            for i in range(layer.output_size):\n",
        "                ################################################\n",
        "                ##\n",
        "                ##   (Equation 15 - Doubly stochastic DGP paper)\n",
        "                ##\n",
        "                ################################################\n",
        "\n",
        "                posterior=layer.posteriors[i]\n",
        "                # Draw a sample from the variational posterior\n",
        "#                 latent_sample = posterior.sample()\n",
        "#                 latent_sample=layer(self.sess,feed_dict)\n",
        "\n",
        "#                 lat=self.sess.run(latent_sample,feed_dict)\n",
        "#                 print(lat)\n",
        "#                 mean,var=tf.nn.moments(latent_sample,axes=0)\n",
        "#                 covariance=tfp.stats.covariance(latent_sample,latent_sample,sample_axis=0, event_axis=None)\n",
        "\n",
        "                mean=posterior.mean()\n",
        "                covariance=posterior.scale.matmul(posterior.scale.to_dense(), adjoint_arg=True)\n",
        "\n",
        "                m,cov=self.sess.run([mean,covariance],feed_dict)\n",
        "                first_term=m\n",
        "                \n",
        "                size=m.size\n",
        "                k=np.eye(size,dtype=np.float64)\n",
        "                z=np.zeros(size,dtype=np.float64)\n",
        "                e=np.random.multivariate_normal(z,k)\n",
        "                sqr=np.sqrt(cov)\n",
        "                print(\"cov\",sqr.size,np.isnan(sqr).sum())\n",
        "                \n",
        "                # TODO check sampe's variance in variational GP class\n",
        "                second_term= np.dot(sqr,e)\n",
        "                print(\"sec\",second_term)\n",
        "                \n",
        "                layer_pred=first_term + second_term\n",
        "                #print(e,np.sqrt(v))\n",
        "                f_i=layer_pred\n",
        "                print(f_i.shape)\n",
        "                print(\"111111111\")\n",
        "#                 print(f_i)\n",
        "\n",
        "            count+=1\n",
        "            print(\"f_i\",f_i)\n",
        "        Y=f_i\n",
        "        return Y\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "A3GnCCbZsVLY",
        "outputId": "b0262d6b-ca22-47e6-ea24-007861c47a7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 938
        }
      },
      "source": [
        "tf.reset_default_graph()\n",
        "print(x.shape)\n",
        "x=x.reshape((-1,1))\n",
        "y=y.reshape((-1,1))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(200, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eik9qgJ1wVqM",
        "colab_type": "code",
        "colab": {},
        "outputId": "0db6fb35-a2ef-41f4-98f3-0594758a4136"
      },
      "source": [
        "dgp=DGP(x,y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/home/ali/.local/lib/python3.6/site-packages/tensorflow_probability/python/distributions/gaussian_process.py:303: UserWarning: Unable to detect statically whether the number of index_points is 1. As a result, defaulting to treating the marginal GP at `index_points` as a multivariate Gaussian. This makes some methods, like `cdf` unavailable.\n",
            "  'Unable to detect statically whether the number of index_points is '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OiVB8Xyxvxl-",
        "colab": {},
        "outputId": "25785e61-f08d-4f2e-e945-6f1698e35801"
      },
      "source": [
        "dgp.train()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.3132616875182228, 1.3132616875182228, 1.3132616875182228]\n",
            "[1.3132616875182228, 1.3132616875182228, 1.3132616875182228]\n",
            "[1.3132616875182228, 1.3132616875182228, 1.3132616875182228]\n",
            "[1.3132616875182228, 1.3132616875182228, 1.3132616875182228]\n",
            "0 215441.2588463236\n",
            "[1.313992844422386, 1.312530727225991, 1.3132616875182228]\n",
            "[1.3139928444222198, 1.3125307272260116, 1.3132616875182228]\n",
            "[1.3139928444201001, 1.3125307272262914, 1.3132616875182228]\n",
            "[1.313992844421744, 1.3125307272260736, 1.3132616875182228]\n",
            "1 219535.3976312049\n",
            "[1.3147250536702892, 1.3117990908752715, 1.3132616875182228]\n",
            "[1.3145200166677904, 1.3120020227624885, 1.3132616875182228]\n",
            "[1.3147132064874238, 1.311810853523024, 1.3132616875182228]\n",
            "[1.3146031547695571, 1.3119181252225667, 1.3132616875182228]\n",
            "2 216232.7716873261\n",
            "[1.3154588726902046, 1.3110662124739103, 1.3132616875182228]\n",
            "[1.3151323782469906, 1.3113886099904553, 1.3132616875182228]\n",
            "[1.3154370681551806, 1.3110883724556885, 1.3132616875182228]\n",
            "[1.3151772550673384, 1.3113423353328937, 1.3132616875182228]\n",
            "3 173424.5444480525\n",
            "[1.3161948501888205, 1.31033153702536, 1.3132616875182228]\n",
            "[1.315606993936831, 1.31088288930532, 1.3132616875182228]\n",
            "[1.315895250533057, 1.3114404245618916, 1.3132616875182228]\n",
            "[1.3156091868059112, 1.3117368974594648, 1.3132616875182228]\n",
            "4 209549.0021290753\n",
            "[1.3169335108793145, 1.309594535715771, 1.3132616875182228]\n",
            "[1.3160483060686896, 1.3103927014429069, 1.3132616875182228]\n",
            "[1.3162985453298435, 1.311702376350846, 1.3132616875182228]\n",
            "[1.3159866247596559, 1.3120215896132357, 1.3132616875182228]\n",
            "5 215003.2611843503\n",
            "[1.3176753627529256, 1.308854698426381, 1.3132616875182228]\n",
            "[1.3164411343429234, 1.3099490241945027, 1.3132616875182228]\n",
            "[1.3166505683614709, 1.3119175515520465, 1.3132616875182228]\n",
            "[1.3163131678167457, 1.3122616692289786, 1.3132616875182228]\n",
            "6 210164.12641553275\n",
            "[1.3184208991258395, 1.3081115315094725, 1.3132616875182228]\n",
            "[1.3168162416799651, 1.309509736365188, 1.3132616875182228]\n",
            "[1.3169799936500755, 1.31205762278174, 1.3132616875182228]\n",
            "[1.3166000795805353, 1.312464056297317, 1.3132616875182228]\n",
            "7 187696.3644650969\n",
            "[1.3191705914196319, 1.3073645649951688, 1.3132616875182228]\n",
            "[1.3172784029552682, 1.3089873010200728, 1.3132616875182228]\n",
            "[1.3174394754131409, 1.3117673154423184, 1.3132616875182228]\n",
            "[1.316861027100901, 1.31261145296595, 1.3132616875182228]\n",
            "8 201352.9309892371\n",
            "[1.319924893787572, 1.3066133479955298, 1.3132616875182228]\n",
            "[1.3178038231890405, 1.3084043860739294, 1.3132616875182228]\n",
            "[1.3178481013722034, 1.3115085622399807, 1.3132616875182228]\n",
            "[1.3170937641720424, 1.3127377089669627, 1.3132616875182228]\n",
            "9 209508.64620850113\n",
            "[1.3206842457481864, 1.3058574460319687, 1.3132616875182228]\n",
            "[1.3182865639468797, 1.3078637821004975, 1.3132616875182228]\n",
            "[1.3182407948327135, 1.3112341426220024, 1.3132616875182228]\n",
            "[1.3173007410489095, 1.3128526281281683, 1.3132616875182228]\n",
            "10 148861.06386528228\n",
            "[1.3214490677430377, 1.305096445377888, 1.3132616875182228]\n",
            "[1.318844981746308, 1.3072658489107574, 1.3132616875182228]\n",
            "[1.3186616763925127, 1.3108165939150027, 1.3132616875182228]\n",
            "[1.3174901417090168, 1.3129436106404238, 1.3132616875182228]\n",
            "11 134161.8140347495\n",
            "[1.322219763985922, 1.3043299501579482, 1.3132616875182228]\n",
            "[1.319458564901076, 1.3066238842100646, 1.3132616875182228]\n",
            "[1.3191689487914908, 1.310342382069204, 1.3132616875182228]\n",
            "[1.317662951644314, 1.313018165138502, 1.3132616875182228]\n",
            "12 205888.05560985746\n",
            "[1.322996724033027, 1.3035575807372384, 1.3132616875182228]\n",
            "[1.320020699988738, 1.30603161285951, 1.3132616875182228]\n",
            "[1.3196264729533134, 1.3099144012133461, 1.3132616875182228]\n",
            "[1.3178206423351457, 1.313078569974709, 1.3132616875182228]\n",
            "13 207016.208353751\n",
            "[1.323780318427349, 1.3027789779610175, 1.3132616875182228]\n",
            "[1.320533681471657, 1.3054886560537884, 1.3132616875182228]\n",
            "[1.3200400479248837, 1.3095270822896719, 1.3132616875182228]\n",
            "[1.3179627313591291, 1.313135360184631, 1.3132616875182228]\n",
            "14 197980.9677995675\n",
            "[1.3245709017962268, 1.301993799920527, 1.3132616875182228]\n",
            "[1.3210197900492289, 1.304963912302813, 1.3132616875182228]\n",
            "[1.3204171473904283, 1.3091649614412049, 1.3132616875182228]\n",
            "[1.3180929826511352, 1.313180851694886, 1.3132616875182228]\n",
            "15 187709.50243888167\n",
            "[1.3253688089627802, 1.3012017256099035, 1.3132616875182228]\n",
            "[1.3215447413706354, 1.3043887723619572, 1.3132616875182228]\n",
            "[1.3207664620245696, 1.3088063710876217, 1.3132616875182228]\n",
            "[1.3182105861815154, 1.3132239579495129, 1.3132616875182228]\n",
            "16 195899.7930854049\n",
            "[1.3261743577570981, 1.3004024518966735, 1.3132616875182228]\n",
            "[1.3220326649243037, 1.3038495179883314, 1.3132616875182228]\n",
            "[1.3210842233681468, 1.3084778596837727, 1.3132616875182228]\n",
            "[1.3183177672967636, 1.3132618658272, 1.3132616875182228]\n",
            "17 167940.68561907686\n",
            "[1.3269878456639914, 1.2995956966084512, 1.3132616875182228]\n",
            "[1.3225484481883618, 1.3032759039772561, 1.3132616875182228]\n",
            "[1.3214213125082124, 1.3080583483365933, 1.3132616875182228]\n",
            "[1.318426425624882, 1.313249943099221, 1.3132616875182228]\n",
            "18 187670.275394453\n",
            "[1.327809552399629, 1.298781195753191, 1.3132616875182228]\n",
            "[1.323025758229908, 1.3027427523950939, 1.3132616875182228]\n",
            "[1.3217307405809744, 1.3076659318672679, 1.3132616875182228]\n",
            "[1.3185270496897497, 1.313233552055703, 1.3132616875182228]\n",
            "19 182160.503560479\n",
            "[1.3286397369155747, 1.2979587062968079, 1.3132616875182228]\n",
            "[1.3234715292979793, 1.3022408303065465, 1.3132616875182228]\n",
            "[1.322013129078519, 1.3073053692039511, 1.3132616875182228]\n",
            "[1.3186232050263467, 1.3131993776473814, 1.3132616875182228]\n",
            "20 178767.35379975138\n",
            "[1.3294786396617473, 1.2971280037649406, 1.3132616875182228]\n",
            "[1.3239801615990363, 1.301669951148031, 1.3132616875182228]\n",
            "[1.3222712032062784, 1.3069734324746678, 1.3132616875182228]\n",
            "[1.3187116225460371, 1.3131619810249893, 1.3132616875182228]\n",
            "21 188039.56747200043\n",
            "[1.3303264797470762, 1.2962888849396372, 1.3132616875182228]\n",
            "[1.3244549738769462, 1.3011341175353544, 1.3132616875182228]\n",
            "[1.3225068403855744, 1.306668630459246, 1.3132616875182228]\n",
            "[1.3187936693462676, 1.3131221312106252, 1.3132616875182228]\n",
            "22 190997.8727334411\n",
            "[1.3311834570120844, 1.29544116573314, 1.3132616875182228]\n",
            "[1.3248917865723695, 1.3006400869500956, 1.3132616875182228]\n",
            "[1.3227222227667486, 1.3063880715958407, 1.3132616875182228]\n",
            "[1.3188598977183257, 1.3131186753448092, 1.3132616875182228]\n",
            "23 69210.71177137546\n",
            "[1.3320497495061612, 1.2945846836590906, 1.3132616875182228]\n",
            "[1.325447927200846, 1.3000491391950928, 1.3132616875182228]\n",
            "[1.3231221306669405, 1.3061770400340316, 1.3132616875182228]\n",
            "[1.3189272000040093, 1.31310036865694, 1.3132616875182228]\n",
            "24 162446.42348680345\n",
            "[1.3329255157457187, 1.2937192956361308, 1.3132616875182228]\n",
            "[1.3259660327375775, 1.2994919919974433, 1.3132616875182228]\n",
            "[1.323489444725032, 1.3059706028547593, 1.3132616875182228]\n",
            "[1.3189708700545892, 1.3131537284875063, 1.3132616875182228]\n",
            "25 170626.73339143224\n",
            "[1.333810894039076, 1.2928448787799272, 1.3132616875182228]\n",
            "[1.3264412963862344, 1.2989796498163624, 1.3132616875182228]\n",
            "[1.323824599448044, 1.3057799764901294, 1.3132616875182228]\n",
            "[1.3189893795323282, 1.3132768918076902, 1.3132616875182228]\n",
            "26 163290.7023966334\n",
            "[1.3347060027007611, 1.2919613304290114, 1.3132616875182228]\n",
            "[1.3269125058612465, 1.298457641472532, 1.3132616875182228]\n",
            "[1.3241362146099969, 1.3055737481837095, 1.3132616875182228]\n",
            "[1.3190032529994429, 1.313409517325276, 1.3132616875182228]\n",
            "27 47587.47960711375\n",
            "[1.33561094442774, 1.29106856420498, 1.3132616875182228]\n",
            "[1.3274861053478586, 1.2978353251581265, 1.3132616875182228]\n",
            "[1.3245445653089822, 1.3052114138647772, 1.3132616875182228]\n",
            "[1.3190220330329565, 1.3135729977704962, 1.3132616875182228]\n",
            "28 -24138.52874274095\n",
            "[1.3365258088248668, 1.2901665080273774, 1.3132616875182228]\n",
            "[1.3280127298529794, 1.29725971228328, 1.3132616875182228]\n",
            "[1.3249922072413847, 1.304714307606616, 1.3132616875182228]\n",
            "[1.3191081852318067, 1.3134785399227087, 1.3132616875182228]\n",
            "29 173342.17996318213\n",
            "[1.337450675887913, 1.289255101187373, 1.3132616875182228]\n",
            "[1.3284958635247806, 1.2967275939899432, 1.3132616875182228]\n",
            "[1.325401202558961, 1.3042574407395855, 1.3132616875182228]\n",
            "[1.31917080001641, 1.3134421971748838, 1.3132616875182228]\n",
            "30 -58676.96548793074\n",
            "[1.3383856218632588, 1.2883342888738745, 1.3132616875182228]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[1.329015469915716, 1.296118749922587, 1.3132616875182228]\n",
            "[1.3257863231753455, 1.3038000520499762, 1.3132616875182228]\n",
            "[1.318869484626484, 1.3138567362739209, 1.3132616875182228]\n",
            "31 165076.60661097744\n",
            "[1.3393307203789928, 1.2874040209962436, 1.3132616875182228]\n",
            "[1.3294943764254727, 1.295552082333207, 1.3132616875182228]\n",
            "[1.3261381233311, 1.3033801368279974, 1.3132616875182228]\n",
            "[1.318580169859499, 1.3142420548024, 1.3132616875182228]\n",
            "32 -1070924.2318180236\n",
            "[1.3402860414005127, 1.2864642528045902, 1.3132616875182228]\n",
            "[1.3300773718567787, 1.294891015632944, 1.3132616875182228]\n",
            "[1.326664302651914, 1.3029000401694233, 1.3132616875182228]\n",
            "[1.3187467156025177, 1.3143719037832695, 1.3132616875182228]\n",
            "33 -502089.28700153425\n",
            "[1.341251651239714, 1.2855149442904825, 1.3132616875182228]\n",
            "[1.3306870796263794, 1.2941832017318895, 1.3132616875182228]\n",
            "[1.3271472601709324, 1.3024455034910678, 1.3132616875182228]\n",
            "[1.3185465592785988, 1.3147594352134493, 1.3132616875182228]\n",
            "34 -1295627.1323775686\n",
            "[1.3422276092680625, 1.284556062809973, 1.3132616875182228]\n",
            "[1.3313272408507792, 1.2934306114848686, 1.3132616875182228]\n",
            "[1.3277590656074723, 1.3020099743696616, 1.3132616875182228]\n",
            "[1.318726308476908, 1.3147104369286498, 1.3132616875182228]\n",
            "35 2002.9094377937727\n",
            "[1.3432139657776332, 1.283587584658701, 1.3132616875182228]\n",
            "[1.3320580235362725, 1.2926176620880117, 1.3132616875182228]\n",
            "[1.3283176880578011, 1.301607439674174, 1.3132616875182228]\n",
            "[1.3188461315066147, 1.3146988447309762, 1.3132616875182228]\n",
            "36 -2000969.121809642\n",
            "[1.3442107597482023, 1.2826094968774813, 1.3132616875182228]\n",
            "[1.3327946836964404, 1.2917843877392667, 1.3132616875182228]\n",
            "[1.3288329312743894, 1.3012022541356492, 1.3132616875182228]\n",
            "[1.318443039306826, 1.3151147231827625, 1.3132616875182228]\n",
            "37 -1149712.7993518622\n",
            "[1.3452180199544332, 1.2816217959360219, 1.3132616875182228]\n",
            "[1.3336050997727502, 1.290902116074534, 1.3132616875182228]\n",
            "[1.3293033446106366, 1.3008263050224873, 1.3132616875182228]\n",
            "[1.3181550164129916, 1.3153714372715495, 1.3132616875182228]\n",
            "38 39145.40379248309\n",
            "[1.3462357643388903, 1.2806244882568345, 1.3132616875182228]\n",
            "[1.334428905529146, 1.2899978262730987, 1.3132616875182228]\n",
            "[1.3297837900438647, 1.3003081487517434, 1.3132616875182228]\n",
            "[1.3178903385055334, 1.3156067599087304, 1.3132616875182228]\n",
            "39 -1491864.557188726\n",
            "[1.347264000728155, 1.2796175895108128, 1.3132616875182228]\n",
            "[1.3353131103464846, 1.2890551058383348, 1.3132616875182228]\n",
            "[1.330407724924969, 1.2996974011692424, 1.3132616875182228]\n",
            "[1.3175928610166114, 1.3159228384074226, 1.3132616875182228]\n",
            "40 -1217061.7028436486\n",
            "[1.3483027277726223, 1.278601123739361, 1.3132616875182228]\n",
            "[1.3361408925840836, 1.288160153799104, 1.3132616875182228]\n",
            "[1.330977605227807, 1.2991298992243472, 1.3132616875182228]\n",
            "[1.3171816769186677, 1.3163206100688052, 1.3132616875182228]\n",
            "41 -2208589.2578338003\n",
            "[1.3493519359021282, 1.2775751224723513, 1.3132616875182228]\n",
            "[1.3369973688130405, 1.2872369862856543, 1.3132616875182228]\n",
            "[1.3315310605642134, 1.298487120484619, 1.3132616875182228]\n",
            "[1.3172327426465453, 1.3162029218444684, 1.3132616875182228]\n",
            "42 85014.75544232248\n",
            "[1.3504116081498114, 1.2765396239670896, 1.3132616875182228]\n",
            "[1.3377853613070152, 1.286380182258499, 1.3132616875182228]\n",
            "[1.3320355026671344, 1.2978978896651179, 1.3132616875182228]\n",
            "[1.3172765787360103, 1.3160982838867994, 1.3132616875182228]\n",
            "43 -242767.27981435586\n",
            "[1.3514817207821126, 1.2754946726238907, 1.3132616875182228]\n",
            "[1.3386526379024282, 1.285478685120432, 1.3132616875182228]\n",
            "[1.3326842009254736, 1.297228379401891, 1.3132616875182228]\n",
            "[1.3173175251714317, 1.316002119130341, 1.3132616875182228]\n",
            "44 86144.62163695632\n",
            "[1.3525622429998727, 1.2744403193002647, 1.3132616875182228]\n",
            "[1.3394683390190574, 1.284610499696623, 1.3132616875182228]\n",
            "[1.3332777080672058, 1.2965995670929513, 1.3132616875182228]\n",
            "[1.3173544488861682, 1.315914975115039, 1.3132616875182228]\n",
            "45 -928528.0183751897\n",
            "[1.353653138709603, 1.2733766196062617, 1.3132616875182228]\n",
            "[1.3402250629559187, 1.2837905612281137, 1.3132616875182228]\n",
            "[1.3338215632328543, 1.296003570965545, 1.3132616875182228]\n",
            "[1.3174271471364933, 1.315795391764781, 1.3132616875182228]\n",
            "46 -709651.232483268\n",
            "[1.3547543659903778, 1.2723036344614393, 1.3132616875182228]\n",
            "[1.340986490523957, 1.2829341285411338, 1.3132616875182228]\n",
            "[1.3343169778884405, 1.2954566500402607, 1.3132616875182228]\n",
            "[1.3174905307952216, 1.315691488457717, 1.3132616875182228]\n",
            "47 -830505.8178593264\n",
            "[1.3558658773046965, 1.2712214299387434, 1.3132616875182228]\n",
            "[1.3418436090548629, 1.2820395354982093, 1.3132616875182228]\n",
            "[1.3349323900544392, 1.294756459254456, 1.3132616875182228]\n",
            "[1.3175625463027423, 1.3155812079013243, 1.3132616875182228]\n",
            "48 35642.25313994897\n",
            "[1.356987619745116, 1.270130077085428, 1.3132616875182228]\n",
            "[1.3426734394360291, 1.2811245801610223, 1.3132616875182228]\n",
            "[1.3354955249004046, 1.2941016006085593, 1.3132616875182228]\n",
            "[1.317626390918785, 1.3154824497735549, 1.3132616875182228]\n",
            "49 -72927.04711431978\n",
            "[1.358119535345879, 1.2690296516867878, 1.3132616875182228]\n",
            "[1.3435021029400873, 1.2801724008825288, 1.3132616875182228]\n",
            "[1.336011551420413, 1.2934856375048527, 1.3132616875182228]\n",
            "[1.317671776108788, 1.3154048907666158, 1.3132616875182228]\n",
            "50 -1176982.782785218\n",
            "[1.3592615614469234, 1.267920233973414, 1.3132616875182228]\n",
            "[1.344399658929068, 1.2791725259379894, 1.3132616875182228]\n",
            "[1.336680243042637, 1.2927257234614236, 1.3132616875182228]\n",
            "[1.317759795047661, 1.3153114901016205, 1.3132616875182228]\n",
            "51 -754601.3077846994\n",
            "[1.3604136310789432, 1.2668019082939923, 1.3132616875182228]\n",
            "[1.3453646833588444, 1.2781338102973618, 1.3132616875182228]\n",
            "[1.3374812886421583, 1.2918774316344035, 1.3132616875182228]\n",
            "[1.3178138391962875, 1.315296809212256, 1.3132616875182228]\n",
            "52 -253801.34645733132\n",
            "[1.361575673305598, 1.2656747628084377, 1.3132616875182228]\n",
            "[1.3462734946965684, 1.2771141794656506, 1.3132616875182228]\n",
            "[1.3382121043893662, 1.2910931716356648, 1.3132616875182228]\n",
            "[1.3178074807202136, 1.315336985428234, 1.3132616875182228]\n",
            "53 -190132.53546935235\n",
            "[1.362747614162346, 1.2645388885864322, 1.3132616875182228]\n",
            "[1.3471179239220263, 1.2761409921326754, 1.3132616875182228]\n",
            "[1.3388787931978827, 1.290368072420773, 1.3132616875182228]\n",
            "[1.3177719790773585, 1.3154019431622967, 1.3132616875182228]\n",
            "54 -1668420.0810292817\n",
            "[1.3639293756091353, 1.2633943806387056, 1.3132616875182228]\n",
            "[1.3480396210440948, 1.2751259462911708, 1.3132616875182228]\n",
            "[1.339595122535745, 1.2899927597260061, 1.3132616875182228]\n",
            "[1.3176736898737809, 1.315570293678756, 1.3132616875182228]\n",
            "55 -3651488.3746047444\n",
            "[1.3651208767527068, 1.2622413367879686, 1.3132616875182228]\n",
            "[1.3490376991602833, 1.274063320545211, 1.3132616875182228]\n",
            "[1.3404369528142315, 1.2895120813537033, 1.3132616875182228]\n",
            "[1.3171955549906245, 1.3161049429095217, 1.3132616875182228]\n",
            "56 -17053873.484861918\n",
            "[1.3663220348418061, 1.261079856816769, 1.3132616875182228]\n",
            "[1.3500977600339252, 1.2729749817604268, 1.3132616875182228]\n",
            "[1.3413558793747449, 1.2889960491226486, 1.3132616875182228]\n",
            "[1.3165437395818025, 1.3167951832569802, 1.3132616875182228]\n",
            "57 -6097782.280312295\n",
            "[1.3675327665583523, 1.2599100413435291, 1.3132616875182228]\n",
            "[1.3512082876403169, 1.2718560817017837, 1.3132616875182228]\n",
            "[1.342356144107088, 1.2883616442912809, 1.3132616875182228]\n",
            "[1.3159709543969074, 1.3174183475423782, 1.3132616875182228]\n",
            "58 -3510457.479632982\n",
            "[1.368752989100495, 1.2587319908427363, 1.3132616875182228]\n",
            "[1.3523625152544299, 1.2707108383093912, 1.3132616875182228]\n",
            "[1.343422501836746, 1.288012381522972, 1.3132616875182228]\n",
            "[1.315467867843532, 1.3179782433421214, 1.3132616875182228]\n",
            "59 -1171420.3014770725\n",
            "[1.3699826205950052, 1.2575458052068498, 1.3132616875182228]\n",
            "[1.3535312257734653, 1.2696128994947329, 1.3132616875182228]\n",
            "[1.3445123881309595, 1.2876438073724705, 1.3132616875182228]\n",
            "[1.3150144096954592, 1.3184847083524385, 1.3132616875182228]\n",
            "60 -916977.2719271353\n",
            "[1.3712215803311567, 1.2563515833854422, 1.3132616875182228]\n",
            "[1.354705043681452, 1.26850351518531, 1.3132616875182228]\n",
            "[1.345623024007132, 1.2873355474574106, 1.3132616875182228]\n",
            "[1.314603924079414, 1.318943535873194, 1.3132616875182228]\n",
            "61 -372165.84684866655\n",
            "[1.3724697864905624, 1.255149425399716, 1.3132616875182228]\n",
            "[1.3557731346710584, 1.2674867186097474, 1.3132616875182228]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[1.346658795807237, 1.2868803251241536, 1.3132616875182228]\n",
            "[1.3142330130860935, 1.3193583862320017, 1.3132616875182228]\n",
            "62 -1176644.5220913673\n",
            "[1.3737271554838955, 1.2539394328371358, 1.3132616875182228]\n",
            "[1.3568939574946854, 1.2664323002687958, 1.3132616875182228]\n",
            "[1.3476017632670747, 1.286447175999743, 1.3132616875182228]\n",
            "[1.313915761343973, 1.3197243716838714, 1.3132616875182228]\n",
            "63 -700758.5212714014\n",
            "[1.3749936007753216, 1.252721709921681, 1.3132616875182228]\n",
            "[1.3580416482100826, 1.265429161479374, 1.3132616875182228]\n",
            "[1.3485279895123508, 1.285813813327458, 1.3132616875182228]\n",
            "[1.3136300999059969, 1.3200550399853157, 1.3132616875182228]\n",
            "64 -1393826.76562656\n",
            "[1.3762690322265576, 1.2514963641775458, 1.3132616875182228]\n",
            "[1.359225938313854, 1.2643576668840768, 1.3132616875182228]\n",
            "[1.3495135969829424, 1.2852192098486495, 1.3132616875182228]\n",
            "[1.313385676688693, 1.3203498541646421, 1.3132616875182228]\n",
            "65 -354400.016537984\n",
            "[1.3775533568838325, 1.25026350579679, 1.3132616875182228]\n",
            "[1.36033919845099, 1.263281254566981, 1.3132616875182228]\n",
            "[1.350447229062838, 1.2845208890173516, 1.3132616875182228]\n",
            "[1.313164486384457, 1.3206168254891593, 1.3132616875182228]\n",
            "66 -702644.3262414732\n",
            "[1.3788464789767003, 1.2490232478381422, 1.3132616875182228]\n",
            "[1.3614964866888506, 1.262184718823144, 1.3132616875182228]\n",
            "[1.3512982401510854, 1.283884744308062, 1.3132616875182228]\n",
            "[1.3129732925724291, 1.3208570520309117, 1.3132616875182228]\n",
            "67 -710335.76271589\n",
            "[1.3801483026977601, 1.2477757038039774, 1.3132616875182228]\n",
            "[1.3626802849158979, 1.2611376750474914, 1.3132616875182228]\n",
            "[1.352099577145813, 1.2831735785784832, 1.3132616875182228]\n",
            "[1.3128040543504467, 1.3210708613777187, 1.3132616875182228]\n",
            "68 -665335.1008401101\n",
            "[1.3814587355920076, 1.2465209846469956, 1.3132616875182228]\n",
            "[1.3638855821579674, 1.260135158861574, 1.3132616875182228]\n",
            "[1.352830106680058, 1.2825071664684553, 1.3132616875182228]\n",
            "[1.3126515985423912, 1.32126377820713, 1.3132616875182228]\n",
            "69 -526193.5872456272\n",
            "[1.3827776902384326, 1.2452591973812541, 1.3132616875182228]\n",
            "[1.3650490672674536, 1.259064305524114, 1.3132616875182228]\n",
            "[1.3535565566229573, 1.2817082481750395, 1.3132616875182228]\n",
            "[1.3125139355589774, 1.321438116225674, 1.3132616875182228]\n",
            "70 -904890.8178475956\n",
            "[1.384105087119764, 1.2439904424918415, 1.3132616875182228]\n",
            "[1.3662399641812906, 1.2580293776897344, 1.3132616875182228]\n",
            "[1.3543249586427086, 1.2807888656970292, 1.3132616875182228]\n",
            "[1.3123941502723515, 1.3215935861440715, 1.3132616875182228]\n",
            "71 -314296.00480121264\n",
            "[1.3854408564152128, 1.2427148122971283, 1.3132616875182228]\n",
            "[1.3673393336574322, 1.2570160430997026, 1.3132616875182228]\n",
            "[1.3550318842806965, 1.279907853327768, 1.3132616875182228]\n",
            "[1.3122860159702276, 1.321734067283302, 1.3132616875182228]\n",
            "72 -1373107.9999815293\n",
            "[1.38678493690675, 1.2414323919902128, 1.3132616875182228]\n",
            "[1.368487538287951, 1.2560124460294824, 1.3132616875182228]\n",
            "[1.3558380966229706, 1.2789246690334768, 1.3132616875182228]\n",
            "[1.3122026954990211, 1.3218546798302193, 1.3132616875182228]\n",
            "73 -2277758.5914320773\n",
            "[1.3881372757306198, 1.2401432598047706, 1.3132616875182228]\n",
            "[1.3697044391296853, 1.2550102741044367, 1.3132616875182228]\n",
            "[1.356799360028361, 1.2780754897052269, 1.3132616875182228]\n",
            "[1.312145027379781, 1.3219606015749226, 1.3132616875182228]\n",
            "74 -1600367.5077809014\n",
            "[1.3894978277112944, 1.2388474875308961, 1.3132616875182228]\n",
            "[1.370976003790736, 1.2539838641115928, 1.3132616875182228]\n",
            "[1.3576958743819902, 1.2774180150589576, 1.3132616875182228]\n",
            "[1.3121101272882718, 1.3220491255001428, 1.3132616875182228]\n",
            "75 -1156031.2531905854\n",
            "[1.3908665530911506, 1.237545142515902, 1.3132616875182228]\n",
            "[1.3722019759004414, 1.2528912895285047, 1.3132616875182228]\n",
            "[1.3586615143045113, 1.2767669009030327, 1.3132616875182228]\n",
            "[1.3120973814390127, 1.322113615669755, 1.3132616875182228]\n",
            "76 -915819.394703493\n",
            "[1.3922434179226952, 1.2362362870932555, 1.3132616875182228]\n",
            "[1.3734386233031133, 1.2518706920451745, 1.3132616875182228]\n",
            "[1.359544677633772, 1.2761956411700333, 1.3132616875182228]\n",
            "[1.3120859949738246, 1.3221719030519723, 1.3132616875182228]\n",
            "77 -1568997.9945304464\n",
            "[1.3936283927337414, 1.2349209796351648, 1.3132616875182228]\n",
            "[1.374699953127899, 1.2508242514895869, 1.3132616875182228]\n",
            "[1.360468812790976, 1.2754628471091136, 1.3132616875182228]\n",
            "[1.312092034122126, 1.322217841781821, 1.3132616875182228]\n",
            "78 -2137998.79222449\n",
            "[1.3950214537858727, 1.2335992731442258, 1.3132616875182228]\n",
            "[1.3760131538597624, 1.2497436181587247, 1.3132616875182228]\n",
            "[1.361469012453376, 1.2748913995921762, 1.3132616875182228]\n",
            "[1.312118990926689, 1.3222448972633096, 1.3132616875182228]\n",
            "79 -2387275.721951554\n",
            "[1.3964225822269878, 1.2322712158769695, 1.3132616875182228]\n",
            "[1.3773616416899273, 1.2486000960965915, 1.3132616875182228]\n",
            "[1.3625694961972663, 1.2741784209938436, 1.3132616875182228]\n",
            "[1.3121613323678538, 1.3222647749345953, 1.3132616875182228]\n",
            "80 -718546.3073010247\n",
            "[1.3978317651997962, 1.230936850160895, 1.3132616875182228]\n",
            "[1.3786483151105915, 1.2473927215736713, 1.3132616875182228]\n",
            "[1.3635676218154829, 1.27352722680731, 1.3132616875182228]\n",
            "[1.31219930280973, 1.322283103338416, 1.3132616875182228]\n",
            "81 -1224232.3090726768\n",
            "[1.399248994164108, 1.2295962139058132, 1.3132616875182228]\n",
            "[1.3799436338085551, 1.2462085791935509, 1.3132616875182228]\n",
            "[1.3644811333376992, 1.2729035097498989, 1.3132616875182228]\n",
            "[1.3122348337348135, 1.3222985930413171, 1.3132616875182228]\n",
            "82 -2209227.9915647535\n",
            "[1.400674264520407, 1.2282493409307074, 1.3132616875182228]\n",
            "[1.3812915270498538, 1.2450906378937299, 1.3132616875182228]\n",
            "[1.365318438950508, 1.272281556045832, 1.3132616875182228]\n",
            "[1.3122872849713592, 1.3223080292028573, 1.3132616875182228]\n",
            "83 -2638963.514198897\n",
            "[1.402107572305742, 1.2268962640943324, 1.3132616875182228]\n",
            "[1.3826784090477144, 1.2439356637949275, 1.3132616875182228]\n",
            "[1.366252739669321, 1.2717053690833307, 1.3132616875182228]\n",
            "[1.3123508479907802, 1.3223103020890312, 1.3132616875182228]\n",
            "84 -1664226.0116860243\n",
            "[1.4035489126590703, 1.22553701676295, 1.3132616875182228]\n",
            "[1.3840617542391913, 1.2427700371260555, 1.3132616875182228]\n",
            "[1.3671026721894448, 1.2711616607160645, 1.3132616875182228]\n",
            "[1.3124245942727941, 1.3223076779687541, 1.3132616875182228]\n",
            "85 -657780.4812977081\n",
            "[1.404998276261159, 1.2241716361781183, 1.3132616875182228]\n",
            "[1.3853334728073412, 1.2416151213298507, 1.3132616875182228]\n",
            "[1.3678729721049525, 1.2706664535759846, 1.3132616875182228]\n",
            "[1.3124916004891807, 1.3223050625263104, 1.3132616875182228]\n",
            "86 -1303302.388144627\n",
            "[1.40645564834093, 1.2228001643737523, 1.3132616875182228]\n",
            "[1.3865890477438414, 1.2404130110305354, 1.3132616875182228]\n",
            "[1.3685867425023495, 1.2701241867863746, 1.3132616875182228]\n",
            "[1.3125532605424124, 1.3223017292832255, 1.3132616875182228]\n",
            "87 -3277519.0928692953\n",
            "[1.407921006331309, 1.2214226503313543, 1.3132616875182228]\n",
            "[1.3879042471635705, 1.23916598114075, 1.3132616875182228]\n",
            "[1.3694748618295491, 1.2694072959810077, 1.3132616875182228]\n",
            "[1.3126293181831452, 1.3222939575625112, 1.3132616875182228]\n",
            "88 -1760019.5632057865\n",
            "[1.4093943206616486, 1.2200391491479652, 1.3132616875182228]\n",
            "[1.389220909239839, 1.2379807981552033, 1.3132616875182228]\n",
            "[1.3703217739410798, 1.2685769995314313, 1.3132616875182228]\n",
            "[1.312706692949157, 1.3222819865416293, 1.3132616875182228]\n",
            "89 -3280422.043015509\n",
            "[1.4108755552353531, 1.218649721483417, 1.3132616875182228]\n",
            "[1.3905875706705182, 1.2367420359769523, 1.3132616875182228]\n",
            "[1.3712772135273317, 1.2677831343822619, 1.3132616875182228]\n",
            "[1.3127976408683306, 1.3222657312215427, 1.3132616875182228]\n",
            "90 -1812664.7476310406\n",
            "[1.412364669062514, 1.2172544319234873, 1.3132616875182228]\n",
            "[1.3919503630587196, 1.2355456069530684, 1.3132616875182228]\n",
            "[1.3721443988331867, 1.2670597354429836, 1.3132616875182228]\n",
            "[1.312887966234291, 1.322246837894908, 1.3132616875182228]\n",
            "91 -3515630.529166802\n",
            "[1.4138616200098275, 1.2158533453909173, 1.3132616875182228]\n",
            "[1.3933633378863686, 1.2343913451606385, 1.3132616875182228]\n",
            "[1.3731221353705356, 1.2663185864037327, 1.3132616875182228]\n",
            "[1.312979950976026, 1.3222244905568314, 1.3132616875182228]\n",
            "92 -3892035.0623956397\n",
            "[1.4153663666307958, 1.2144465254204304, 1.3132616875182228]\n",
            "[1.3947974258943643, 1.2331620003502748, 1.3132616875182228]\n",
            "[1.374244175101734, 1.2657987095790246, 1.3132616875182228]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[1.3130854137919166, 1.3222000640146543, 1.3132616875182228]\n",
            "93 -1997922.363926072\n",
            "[1.4168788686269749, 1.213034033790104, 1.3132616875182228]\n",
            "[1.3962170012113588, 1.2319709813809827, 1.3132616875182228]\n",
            "[1.3752645940468549, 1.2653130081458162, 1.3132616875182228]\n",
            "[1.3131806711209246, 1.3221782242909657, 1.3132616875182228]\n",
            "94 -3593744.1185904797\n",
            "[1.4183990869634038, 1.211615930544013, 1.3132616875182228]\n",
            "[1.397644419114813, 1.2307259791326786, 1.3132616875182228]\n",
            "[1.376393389930845, 1.2646010262710774, 1.3132616875182228]\n",
            "[1.313287627019274, 1.3221531569674663, 1.3132616875182228]\n",
            "95 -2587497.018625767\n",
            "[1.4199269810571638, 1.2101922767689337, 1.3132616875182228]\n",
            "[1.3990616352332548, 1.2295155986873325, 1.3132616875182228]\n",
            "[1.3774587996894796, 1.2637406897392627, 1.3132616875182228]\n",
            "[1.3134044448680096, 1.3221253453656174, 1.3132616875182228]\n",
            "96 -4674348.497620381\n",
            "[1.4214625062319, 1.2087631370694312, 1.3132616875182228]\n",
            "[1.4005253084112774, 1.2283268794229594, 1.3132616875182228]\n",
            "[1.378628055313591, 1.263331657269416, 1.3132616875182228]\n",
            "[1.3135299425006395, 1.3220929249508806, 1.3132616875182228]\n",
            "97 -2624817.161588996\n",
            "[1.4230056117325618, 1.2073285814247012, 1.3132616875182228]\n",
            "[1.4019664741907503, 1.2271064635716922, 1.3132616875182228]\n",
            "[1.3797466044985907, 1.2626808072174178, 1.3132616875182228]\n",
            "[1.313666585976685, 1.3220440044141442, 1.3132616875182228]\n",
            "98 -5099498.137077951\n",
            "[1.4245562419838933, 1.2058886839536462, 1.3132616875182228]\n",
            "[1.4034510322786462, 1.2259002014356293, 1.3132616875182228]\n",
            "[1.3809646934963136, 1.2618703899167347, 1.3132616875182228]\n",
            "[1.3138114284946205, 1.321994254161631, 1.3132616875182228]\n",
            "99 -4739541.081373307\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "E60dRtsDwVqR",
        "colab_type": "code",
        "colab": {},
        "outputId": "e1a14222-3351-4283-e76d-a15591450da6"
      },
      "source": [
        "print(dgp.predict(x))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/home/ali/.local/lib/python3.6/site-packages/ipykernel_launcher.py:137: RuntimeWarning: invalid value encountered in sqrt\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "cov 40000 19436\n",
            "sec [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan]\n",
            "(200,)\n",
            "111111111\n",
            "f_i [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan]\n",
            "cov 40000 40000\n",
            "sec [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan]\n",
            "(200,)\n",
            "111111111\n",
            "f_i [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan]\n",
            "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3GvL0Li6wVqU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}